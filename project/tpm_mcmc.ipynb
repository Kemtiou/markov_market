{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import glob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get complete dataframe for one customer : \n",
    "- columns = ['timestamp', 'customer_id', 'location', 'before', 'after']\n",
    "- timestamp : complete from entrance to checkout in 1 minute resolution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def get_one_customer(data, weekday_tag, customer_no):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        data: dataframe - containing data of one weekday\n",
    "        weekday_tag: str - e.g. 'mo','tu','we','th','fr'\n",
    "        ustomer_no: int - as in the data dataframe\n",
    "    output dataframe for one customer: \n",
    "        timestamp : 1min frequency\n",
    "        customer_id : str weekday_tag + customer_no\n",
    "        location : location at correspoinding time \n",
    "    \"\"\"\n",
    "    # get data of one customer\n",
    "    one_customer = data.loc[data['customer_no']==customer_no]\n",
    "    # generate complete time index\n",
    "    one_timeind = pd.date_range(start=one_customer.index[0], end=one_customer.index[-1], freq='min')\n",
    "    # initiate dataframe with complete time index\n",
    "    df_one = pd.DataFrame({'timestamp' : one_timeind})\n",
    "    # modify customer id by adding weekday information\n",
    "    df_one['customer_id'] = weekday_tag + str(customer_no)\n",
    "    # fill in the dataframe :df.resample('min).fillna('ffill')\n",
    "    df_one = df_one.merge(one_customer['location'].reset_index(), on=['timestamp'], how='left').fillna(method='ffill')\n",
    "    \n",
    "    # for consistancy : each customer start with entrance, stop with checkout \n",
    "    df_one['before'] = pd.Series({0 : 'entrance'}).append(df_one['location'][:-1]).values\n",
    "    df_one['after'] = df_one['location']\n",
    "    # if not ended by checkout add one line ending with checkout\n",
    "    if df_one['after'].iloc[-1] != 'checkout':\n",
    "        df_one = df_one.append(df_one.iloc[-1])\n",
    "        df_one['after'].iloc[-1] = 'checkout'\n",
    "\n",
    "    return df_one"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate dataframe containing all customers on monday"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# data_mo = pd.DataFrame(columns=['timestamp', 'customer_id', 'location', 'before', 'after'])\n",
    "# df = pd.read_csv('../data/monday.csv', sep=';', parse_dates=True, index_col=[0])\n",
    "# for i_customers in df['customer_no'].unique():\n",
    "#     one_customer = get_one_customer(df, 'mo', i_customers)\n",
    "#     data_mo = data_mo.append(one_customer)\n",
    "\n",
    "# data_mo.to_csv('data_monday.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate dataframe containing all customers of the whole week"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# data_all = pd.DataFrame(columns=['timestamp', 'customer_id', 'location', 'before', 'after'])\n",
    "# for file in glob.glob('../data/*.csv'):\n",
    "#     weekday_tag = file[8:10]\n",
    "#     print(weekday_tag)\n",
    "#     df = pd.read_csv(file, sep=';', parse_dates=True, index_col=[0])\n",
    "#     for i_customers in df['customer_no'].unique():\n",
    "#         one_customer = get_one_customer(df, weekday_tag, i_customers)\n",
    "#         data_all = data_all.append(one_customer)\n",
    "        \n",
    "# data_all.to_csv('data_week.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate the transformation probability matrix with entire data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def calculate_tpm(data_mo):\n",
    "    \"\"\"\n",
    "    calculate the transformation probability matrix\n",
    "    input : dataframe at least contains a 'before' and an 'after' column\n",
    "    output : dataframe of size n_state x n_state\n",
    "    \"\"\"\n",
    "    # iniciate transformation probability matrix\n",
    "    states = ['entrance', 'dairy', 'drinks', 'fruit','spices','checkout']\n",
    "    tpm = pd.DataFrame(0, index=states, columns=states)\n",
    "    # fill with monday data probabilities\n",
    "    tpm_fill = tpm + pd.crosstab(data_mo['before'], data_mo['after'], normalize=0)\n",
    "    # fillna with probability=0\n",
    "    tpm_fill.fillna(0, inplace=True)\n",
    "    # checkout the absorbtion state\n",
    "    tpm_fill['checkout'].iloc[tpm_fill.index == 'checkout'] = 1\n",
    "    return tpm_fill\n",
    "\n",
    "data_all = pd.read_csv('data_week.csv')\n",
    "tpm = calculate_tpm(data_all)\n",
    "tpm.to_csv('tpm_all.csv')\n",
    "print(tpm.values)\n",
    "print(tpm)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.         0.         0.         0.         0.         0.        ]\n",
      " [0.10291054 0.73720655 0.05860497 0.         0.04987896 0.05139898]\n",
      " [0.21595231 0.01089526 0.59831432 0.         0.08788159 0.08695652]\n",
      " [0.00120741 0.28722833 0.15334049 0.         0.3769788  0.18124497]\n",
      " [0.20160529 0.09592383 0.05484734 0.         0.59694681 0.05067674]\n",
      " [0.15054963 0.19324518 0.16313526 0.         0.09096702 0.40210292]]\n",
      "          checkout     dairy    drinks  entrance     fruit    spices\n",
      "checkout  1.000000  0.000000  0.000000       0.0  0.000000  0.000000\n",
      "dairy     0.102911  0.737207  0.058605       0.0  0.049879  0.051399\n",
      "drinks    0.215952  0.010895  0.598314       0.0  0.087882  0.086957\n",
      "entrance  0.001207  0.287228  0.153340       0.0  0.376979  0.181245\n",
      "fruit     0.201605  0.095924  0.054847       0.0  0.596947  0.050677\n",
      "spices    0.150550  0.193245  0.163135       0.0  0.090967  0.402103\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate customer behaviour : markov chain simulation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def customer_mcmc(tpm):\n",
    "    \"\"\"\n",
    "    simulate customer behavior with markov chain model\n",
    "    input : transition probability matrix\n",
    "    output : list of states starting with entrance and end with checkout\n",
    "    \"\"\"\n",
    "    inside = 1\n",
    "    seq = ['entrance'] # iniciate sequence starting with entrance\n",
    "    while inside:\n",
    "        states = tpm.columns       \n",
    "        state = random.choices(states, weights=tpm.iloc[tpm.index == seq[-1]].values.tolist()[0])\n",
    "        seq += state\n",
    "        if state == ['checkout']:\n",
    "            inside = 0\n",
    "            break\n",
    "        elif len(seq) == 50:\n",
    "            inside = 0\n",
    "            break\n",
    "    return seq\n",
    "\n",
    "seq = customer_mcmc(tpm)\n",
    "seq"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['entrance', 'dairy', 'dairy', 'dairy', 'dairy', 'checkout']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit (conda)"
  },
  "interpreter": {
   "hash": "e693f81ce65b2d86a8ccaa4486a6c3213eba987e9092bbfb488d6be295156d0f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}